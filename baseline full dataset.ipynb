{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0V2ZCsbwszv"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/alexmelekhin/iprofihack2023_place_recognition/blob/main/baseline_demo.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKrvwN96wsz1"
      },
      "source": [
        "## Установка в Google Colab\n",
        "\n",
        "Ячейки ниже рекомендуется использовать для установки зависимостей в Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6ApEuUtwsz2"
      },
      "source": [
        "1. Убедитесь, что вы подключены к окружению с GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zP9eiMddwsz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f727c08a-b177-4ffb-8344-6ef7cd917c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 26 07:37:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BVx-IQ5wsz4"
      },
      "source": [
        "2. По умолчанию установлена версия torch 2.0, нам нужно откатиться до 1.13.1 (код не тестировался на версии 2.0 и может вести себя непредсказуемо)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fMu9bx84wsz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab40a559-7708-411b-c31b-77d927320142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.14.1\n",
            "  Downloading torchvision-0.14.1-cp39-cp39-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1) (2.27.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1) (2022.12.7)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchvision-0.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.1 torchvision==0.14.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZARcL7qiwsz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19ca782-25c2-4401-f3db-e8bd82874b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 1.13.1+cu117\n",
            "Is CUDA available in torch?: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"torch version: {torch.__version__}\")\n",
        "print(f\"Is CUDA available in torch?: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dktavwzNwsz6"
      },
      "source": [
        "3. Установка необходимых библиотек для сборки MinkowskiEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3jxL1-URwsz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270deced-a015-4a93-ca66-4b7a98dadd6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jPyBRtL3wsz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881748bb-8703-450c-a7c3-2335ab9faae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.3.8+ds-1ubuntu0.20.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install libopenblas-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Y9JSMAwsz7"
      },
      "source": [
        "4. Сборка и установка MinkowskiEngine из исходников (занимает много времени)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HQiLBCPgwsz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80285c84-2844-4864-9562-92cba14b66b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.0.1 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\n",
            "\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option / --install-option. Consider using --config-settings for more flexibility.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: --install-option is deprecated because it forces pip to use the 'setup.py install' command which is itself deprecated. pip 23.1 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11358\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/NVIDIA/MinkowskiEngine\n",
            "  Cloning https://github.com/NVIDIA/MinkowskiEngine to /tmp/pip-req-build-88ykiru5\n",
            "  Running command git version\n",
            "  git version 2.25.1\n",
            "  Running command git clone --filter=blob:none https://github.com/NVIDIA/MinkowskiEngine /tmp/pip-req-build-88ykiru5\n",
            "  Cloning into '/tmp/pip-req-build-88ykiru5'...\n",
            "  Updating files:   0% (2/244)\n",
            "  Updating files:   1% (3/244)\n",
            "  Updating files:   2% (5/244)\n",
            "  Updating files:   3% (8/244)\n",
            "  Updating files:   4% (10/244)\n",
            "  Updating files:   5% (13/244)\n",
            "  Updating files:   6% (15/244)\n",
            "  Updating files:   7% (18/244)\n",
            "  Updating files:   8% (20/244)\n",
            "  Updating files:   9% (22/244)\n",
            "  Updating files:  10% (25/244)\n",
            "  Updating files:  11% (27/244)\n",
            "  Updating files:  12% (30/244)\n",
            "  Updating files:  13% (32/244)\n",
            "  Updating files:  14% (35/244)\n",
            "  Updating files:  15% (37/244)\n",
            "  Updating files:  16% (40/244)\n",
            "  Updating files:  17% (42/244)\n",
            "  Updating files:  18% (44/244)\n",
            "  Updating files:  19% (47/244)\n",
            "  Updating files:  20% (49/244)\n",
            "  Updating files:  21% (52/244)\n",
            "  Updating files:  22% (54/244)\n",
            "  Updating files:  23% (57/244)\n",
            "  Updating files:  24% (59/244)\n",
            "  Updating files:  25% (61/244)\n",
            "  Updating files:  26% (64/244)\n",
            "  Updating files:  27% (66/244)\n",
            "  Updating files:  28% (69/244)\n",
            "  Updating files:  29% (71/244)\n",
            "  Updating files:  30% (74/244)\n",
            "  Updating files:  31% (76/244)\n",
            "  Updating files:  32% (79/244)\n",
            "  Updating files:  33% (81/244)\n",
            "  Updating files:  34% (83/244)\n",
            "  Updating files:  35% (86/244)\n",
            "  Updating files:  36% (88/244)\n",
            "  Updating files:  37% (91/244)\n",
            "  Updating files:  38% (93/244)\n",
            "  Updating files:  39% (96/244)\n",
            "  Updating files:  40% (98/244)\n",
            "  Updating files:  41% (101/244)\n",
            "  Updating files:  42% (103/244)\n",
            "  Updating files:  43% (105/244)\n",
            "  Updating files:  44% (108/244)\n",
            "  Updating files:  45% (110/244)\n",
            "  Updating files:  46% (113/244)\n",
            "  Updating files:  47% (115/244)\n",
            "  Updating files:  48% (118/244)\n",
            "  Updating files:  49% (120/244)\n",
            "  Updating files:  50% (122/244)\n",
            "  Updating files:  51% (125/244)\n",
            "  Updating files:  52% (127/244)\n",
            "  Updating files:  53% (130/244)\n",
            "  Updating files:  54% (132/244)\n",
            "  Updating files:  55% (135/244)\n",
            "  Updating files:  56% (137/244)\n",
            "  Updating files:  57% (140/244)\n",
            "  Updating files:  58% (142/244)\n",
            "  Updating files:  59% (144/244)\n",
            "  Updating files:  60% (147/244)\n",
            "  Updating files:  61% (149/244)\n",
            "  Updating files:  62% (152/244)\n",
            "  Updating files:  63% (154/244)\n",
            "  Updating files:  64% (157/244)\n",
            "  Updating files:  65% (159/244)\n",
            "  Updating files:  66% (162/244)\n",
            "  Updating files:  67% (164/244)\n",
            "  Updating files:  68% (166/244)\n",
            "  Updating files:  69% (169/244)\n",
            "  Updating files:  70% (171/244)\n",
            "  Updating files:  71% (174/244)\n",
            "  Updating files:  72% (176/244)\n",
            "  Updating files:  73% (179/244)\n",
            "  Updating files:  74% (181/244)\n",
            "  Updating files:  75% (183/244)\n",
            "  Updating files:  76% (186/244)\n",
            "  Updating files:  77% (188/244)\n",
            "  Updating files:  78% (191/244)\n",
            "  Updating files:  79% (193/244)\n",
            "  Updating files:  80% (196/244)\n",
            "  Updating files:  81% (198/244)\n",
            "  Updating files:  82% (201/244)\n",
            "  Updating files:  83% (203/244)\n",
            "  Updating files:  84% (205/244)\n",
            "  Updating files:  85% (208/244)\n",
            "  Updating files:  86% (210/244)\n",
            "  Updating files:  87% (213/244)\n",
            "  Updating files:  88% (215/244)\n",
            "  Updating files:  89% (218/244)\n",
            "  Updating files:  90% (220/244)\n",
            "  Updating files:  91% (223/244)\n",
            "  Updating files:  92% (225/244)\n",
            "  Updating files:  93% (227/244)\n",
            "  Updating files:  94% (230/244)\n",
            "  Updating files:  95% (232/244)\n",
            "  Updating files:  96% (235/244)\n",
            "  Updating files:  97% (237/244)\n",
            "  Updating files:  98% (240/244)\n",
            "  Updating files:  99% (242/244)\n",
            "  Updating files: 100% (244/244)\n",
            "  Updating files: 100% (244/244), done.\n",
            "  Running command git rev-parse HEAD\n",
            "  02fc608bea4c0549b0a7b00ca1bf15dee4a0b228\n",
            "  Resolved https://github.com/NVIDIA/MinkowskiEngine to commit 02fc608bea4c0549b0a7b00ca1bf15dee4a0b228\n",
            "  Running command git rev-parse HEAD\n",
            "  02fc608bea4c0549b0a7b00ca1bf15dee4a0b228\n",
            "  Running command python setup.py egg_info\n",
            "  WARNING: Skipping MinkowskiEngine as it is not installed.\n",
            "  --------------------------------\n",
            "  | CUDA compilation set         |\n",
            "  --------------------------------\n",
            "\n",
            "  Using BLAS=openblas\n",
            "  Using the default compiler\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-q4msyymp/MinkowskiEngine.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: MinkowskiEngine\n",
            "\u001b[33m  DEPRECATION: MinkowskiEngine is being installed using the legacy 'setup.py install' method, because the '--no-binary' option was enabled for it and this currently disables local wheel building for projects that don't have a 'pyproject.toml' file. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/11451\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command Running setup.py install for MinkowskiEngine\n",
            "  WARNING: Skipping MinkowskiEngine as it is not installed.\n",
            "  --------------------------------\n",
            "  | FORCE_CUDA set                |\n",
            "  --------------------------------\n",
            "  --------------------------------\n",
            "  | CUDA compilation set         |\n",
            "  --------------------------------\n",
            "\n",
            "  Using BLAS=openblas\n",
            "  Using the default compiler\n",
            "  running install\n",
            "  /usr/lib/python3.9/distutils/cmd.py:62: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Please avoid running ``setup.py`` directly.\n",
            "          Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "          other standards-based tools.\n",
            "\n",
            "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    self.initialize_options()\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.9\n",
            "  creating build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiOps.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/sparse_matrix_functions.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiKernelGenerator.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/__init__.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiNetwork.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/diagnostics.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiNormalization.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiFunctional.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiTensorField.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiCoordinateManager.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiBroadcast.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiPooling.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiUnion.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiInterpolation.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiConvolution.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiSparseTensor.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiCommon.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiNonlinearity.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiChannelwiseConvolution.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiPruning.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  copying ./MinkowskiEngine/MinkowskiTensor.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine\n",
            "  creating build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  copying ./MinkowskiEngine/utils/__init__.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  copying ./MinkowskiEngine/utils/init.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  copying ./MinkowskiEngine/utils/coords.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  copying ./MinkowskiEngine/utils/quantization.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  copying ./MinkowskiEngine/utils/summary.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  copying ./MinkowskiEngine/utils/gradcheck.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  copying ./MinkowskiEngine/utils/collation.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/utils\n",
            "  creating build/lib.linux-x86_64-3.9/MinkowskiEngine/modules\n",
            "  copying ./MinkowskiEngine/modules/__init__.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/modules\n",
            "  copying ./MinkowskiEngine/modules/senet_block.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/modules\n",
            "  copying ./MinkowskiEngine/modules/resnet_block.py -> build/lib.linux-x86_64-3.9/MinkowskiEngine/modules\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.8) has a minor version mismatch with the version that was used to compile PyTorch (11.7). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  /usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:397: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "  building 'MinkowskiEngineBackend._C' extension\n",
            "  creating /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9\n",
            "  creating /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp\n",
            "  creating /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5\n",
            "  creating /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src\n",
            "  creating /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/pybind\n",
            "  Emitting ninja build file /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/broadcast_kernel.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/broadcast_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [2/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/broadcast_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/broadcast_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [3/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/convolution_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/convolution_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [4/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/convolution_kernel.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/convolution_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /tmp/pip-req-build-88ykiru5/src/convolution_kernel.cu(334): warning #68-D: integer conversion resulted in a change of sign\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/convolution_kernel.cu(573): warning #68-D: integer conversion resulted in a change of sign\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/convolution_kernel.cu(334): warning #68-D: integer conversion resulted in a change of sign\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/convolution_kernel.cu(573): warning #68-D: integer conversion resulted in a change of sign\n",
            "\n",
            "  [5/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/convolution_transpose_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/convolution_transpose_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [6/21] c++ -MMD -MF /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/direct_max_pool.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/direct_max_pool.cpp -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/direct_max_pool.o -fopenmp -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  [7/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(625): here\n",
            "              instantiation of \"minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::self_type minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_region(minkowski::cpu_kernel_region<coordinate_type> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_type &) const [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(2460): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(625): here\n",
            "              instantiation of \"minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::self_type minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_region(minkowski::cpu_kernel_region<coordinate_type> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_type &) const [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(2460): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(625): here\n",
            "              instantiation of \"minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::self_type minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_region(minkowski::cpu_kernel_region<coordinate_type> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_type &) const [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(2460): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(625): here\n",
            "              instantiation of \"minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::self_type minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_region(minkowski::cpu_kernel_region<coordinate_type> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator>::stride_type &) const [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.cu(2460): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_tensor_stride() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(429): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_kernel_size() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(429): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_dilation() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(430): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_offset() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  [8/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /tmp/pip-req-build-88ykiru5/src/gpu.cu(104): warning #177-D: function \"minkowski::format_size\" was declared but never referenced\n",
            "\n",
            "  [9/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_cpu.hpp(58): warning #177-D: variable \"float_type\" was declared but never referenced\n",
            "            detected during:\n",
            "              instantiation of \"std::pair<at::Tensor, at::Tensor> minkowski::CoordinateMapCPU<coordinate_type, TemplatedAllocator>::field_map(const coordinate_field_type *, minkowski::CoordinateMapCPU<coordinate_type, TemplatedAllocator>::size_type) const [with coordinate_type=int32_t, TemplatedAllocator=std::allocator, coordinate_field_type=float]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(329): here\n",
            "              instantiation of \"std::pair<at::Tensor, at::Tensor> minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::field_to_sparse_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=std::allocator, CoordinateMapType=minkowski::CoordinateMapCPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(1451): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(717): warning #430-D: returning reference to local temporary\n",
            "            detected during instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, __nv_bool, __nv_bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=std::allocator, CoordinateMapType=minkowski::CoordinateMapCPU]\"\n",
            "  (1451): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(717): warning #430-D: returning reference to local temporary\n",
            "            detected during instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, __nv_bool, __nv_bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::default_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(401): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(205): here\n",
            "              instantiation of \"minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>> minkowski::detail::kernel_map_functor<coordinate_type, TemplatedAllocator, minkowski::CoordinateMapGPU, minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>>>::operator()(const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, minkowski::CUDAKernelMapMode::Mode, minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(753): here\n",
            "              instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, __nv_bool, __nv_bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::default_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(401): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(205): here\n",
            "              instantiation of \"minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>> minkowski::detail::kernel_map_functor<coordinate_type, TemplatedAllocator, minkowski::CoordinateMapGPU, minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>>>::operator()(const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, minkowski::CUDAKernelMapMode::Mode, minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(753): here\n",
            "              instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, __nv_bool, __nv_bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::default_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(401): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(205): here\n",
            "              instantiation of \"minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>> minkowski::detail::kernel_map_functor<coordinate_type, TemplatedAllocator, minkowski::CoordinateMapGPU, minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>>>::operator()(const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, minkowski::CUDAKernelMapMode::Mode, minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(753): here\n",
            "              instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, __nv_bool, __nv_bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::default_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(401): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20014-D: calling a __host__ function from a __host__ __device__ function is not allowed\n",
            "            detected during:\n",
            "              instantiation of \"minkowski::gpu_kernel_region<coordinate_type>::gpu_kernel_region(const minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(205): here\n",
            "              instantiation of \"minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>> minkowski::detail::kernel_map_functor<coordinate_type, TemplatedAllocator, minkowski::CoordinateMapGPU, minkowski::gpu_kernel_map<minkowski::type_wrapper<uint32_t, int32_t, float>::index_type, TemplatedAllocator<char>>>::operator()(const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, const minkowski::CoordinateMapGPU<coordinate_type, TemplatedAllocator> &, minkowski::CUDAKernelMapMode::Mode, minkowski::cpu_kernel_region<coordinate_type> &) [with coordinate_type=int32_t, TemplatedAllocator=minkowski::detail::default_allocator]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(753): here\n",
            "              instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, __nv_bool, __nv_bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::default_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(401): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(717): warning #430-D: returning reference to local temporary\n",
            "            detected during instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, __nv_bool, __nv_bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::c10_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(404): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(428): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_tensor_stride() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(429): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_kernel_size() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(429): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_dilation() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp(430): warning #20011-D: calling a __host__ function(\"minkowski::cpu_kernel_region<int> ::device_offset() const\") from a __host__ __device__ function(\"minkowski::gpu_kernel_region<int> ::gpu_kernel_region\") is not allowed\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(717): warning #430-D: returning reference to local temporary\n",
            "            detected during instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, bool, bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=std::allocator, CoordinateMapType=minkowski::CoordinateMapCPU]\"\n",
            "  (1451): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(717): warning #430-D: returning reference to local temporary\n",
            "            detected during instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, bool, bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::default_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(401): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp(717): warning #430-D: returning reference to local temporary\n",
            "            detected during instantiation of \"const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type &minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapKey *, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, const minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type &, minkowski::RegionType::Type, const at::Tensor &, bool, bool) [with coordinate_type=int32_t, coordinate_field_type=float, TemplatedAllocator=minkowski::detail::c10_allocator, CoordinateMapType=minkowski::CoordinateMapGPU]\"\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu(404): here\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp: In instantiation of ‘const kernel_map_type& minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey*, const minkowski::CoordinateMapKey*, const stride_type&, const stride_type&, const stride_type&, minkowski::RegionType::Type, const at::Tensor&, bool, bool) [with coordinate_type = int; coordinate_field_type = float; TemplatedAllocator = std::allocator; CoordinateMapType = minkowski::CoordinateMapCPU; minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type = minkowski::cpu_kernel_map; minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type = std::vector<unsigned int, std::allocator<unsigned int> >]’:\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp:1451:16:   required from here\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp:717:260: warning: returning reference to temporary [-Wreturn-local-addr]\n",
            "    717 |       return detail::empty_map_functor<coordinate_type, TemplatedAllocator,\n",
            "        |                                                                                                                                                                                                                                                                    ^\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp: In instantiation of ‘const kernel_map_type& minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey*, const minkowski::CoordinateMapKey*, const stride_type&, const stride_type&, const stride_type&, minkowski::RegionType::Type, const at::Tensor&, bool, bool) [with coordinate_type = int; coordinate_field_type = float; TemplatedAllocator = minkowski::detail::default_allocator; CoordinateMapType = minkowski::CoordinateMapGPU; minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type = minkowski::gpu_kernel_map<unsigned int, minkowski::detail::default_allocator<char> >; minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type = std::vector<unsigned int, std::allocator<unsigned int> >]’:\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu:401:16:   required from here\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp:717:260: warning: returning reference to temporary [-Wreturn-local-addr]\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp: In instantiation of ‘const kernel_map_type& minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map(const minkowski::CoordinateMapKey*, const minkowski::CoordinateMapKey*, const stride_type&, const stride_type&, const stride_type&, minkowski::RegionType::Type, const at::Tensor&, bool, bool) [with coordinate_type = int; coordinate_field_type = float; TemplatedAllocator = minkowski::detail::c10_allocator; CoordinateMapType = minkowski::CoordinateMapGPU; minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::kernel_map_type = minkowski::gpu_kernel_map<unsigned int, minkowski::detail::c10_allocator<char> >; minkowski::CoordinateMapManager<coordinate_type, coordinate_field_type, TemplatedAllocator, CoordinateMapType>::stride_type = std::vector<unsigned int, std::allocator<unsigned int> >]’:\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cu:404:16:   required from here\n",
            "  /tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.cpp:717:260: warning: returning reference to temporary [-Wreturn-local-addr]\n",
            "  [10/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/global_pooling_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/global_pooling_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [11/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/local_pooling_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/local_pooling_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [12/21] c++ -MMD -MF /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/math_functions_cpu.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/math_functions_cpu.cpp -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/math_functions_cpu.o -fopenmp -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  [13/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/interpolation_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/interpolation_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [14/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/math_functions_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/math_functions_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [15/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/pooling_avg_kernel.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/pooling_avg_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [16/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/local_pooling_transpose_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/local_pooling_transpose_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [17/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/pooling_max_kernel.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/pooling_max_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [18/21] c++ -MMD -MF /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/quantization.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/quantization.cpp -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/quantization.o -fopenmp -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /tmp/pip-req-build-88ykiru5/src/allocators.cuh:39,\n",
            "                   from /tmp/pip-req-build-88ykiru5/src/kernel_region.hpp:40,\n",
            "                   from /tmp/pip-req-build-88ykiru5/src/coordinate_map.hpp:30,\n",
            "                   from /tmp/pip-req-build-88ykiru5/src/coordinate_map_cpu.hpp:28,\n",
            "                   from /tmp/pip-req-build-88ykiru5/src/quantization.cpp:32:\n",
            "  /tmp/pip-req-build-88ykiru5/src/gpu.cuh:149: warning: \"THRUST_CHECK\" redefined\n",
            "    149 | #define THRUST_CHECK(condition)                                                \\\n",
            "        |\n",
            "  In file included from /tmp/pip-req-build-88ykiru5/src/coordinate.hpp:30,\n",
            "                   from /tmp/pip-req-build-88ykiru5/src/coordinate_map.hpp:29,\n",
            "                   from /tmp/pip-req-build-88ykiru5/src/coordinate_map_cpu.hpp:28,\n",
            "                   from /tmp/pip-req-build-88ykiru5/src/quantization.cpp:32:\n",
            "  /tmp/pip-req-build-88ykiru5/src/utils.hpp:169: note: this is the location of the previous definition\n",
            "    169 | #define THRUST_CHECK(condition) condition;\n",
            "        |\n",
            "  /tmp/pip-req-build-88ykiru5/src/quantization.cpp: In function ‘std::vector<std::vector<int> > minkowski::quantize_label(const int*, const int*, int, int, int)’:\n",
            "  /tmp/pip-req-build-88ykiru5/src/quantization.cpp:177:16: warning: variable ‘it’ set but not used [-Wunused-but-set-variable]\n",
            "    177 |     const auto it = map.find(key);\n",
            "        |                ^~\n",
            "  [19/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/pruning_gpu.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/pruning_gpu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  [20/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/src/spmm.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/spmm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  /tmp/pip-req-build-88ykiru5/src/spmm.cu(93): warning #177-D: variable \"is_int64\" was declared but never referenced\n",
            "\n",
            "  /tmp/pip-req-build-88ykiru5/src/spmm.cu(355): warning #177-D: variable \"is_int64\" was declared but never referenced\n",
            "\n",
            "  [21/21] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/tmp/pip-req-build-88ykiru5/src -I/tmp/pip-req-build-88ykiru5/src/3rdparty -I/usr/include/python3.9 -c -c /tmp/pip-req-build-88ykiru5/pybind/minkowski.cu -o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/pybind/minkowski.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' --expt-relaxed-constexpr --expt-extended-lambda -O3 -Xcompiler=-fno-gnu-unique -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  creating build/lib.linux-x86_64-3.9/MinkowskiEngineBackend\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/broadcast_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/broadcast_kernel.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/convolution_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/convolution_kernel.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/convolution_transpose_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/coordinate_map_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/coordinate_map_manager.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/direct_max_pool.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/global_pooling_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/interpolation_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/local_pooling_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/local_pooling_transpose_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/math_functions_cpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/math_functions_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/pooling_avg_kernel.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/pooling_max_kernel.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/pruning_gpu.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/quantization.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/tmp/pip-req-build-88ykiru5/src/spmm.o /tmp/pip-req-build-88ykiru5/build/temp.linux-x86_64-3.9/pybind/minkowski.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lcusparse -lopenblas -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/MinkowskiEngineBackend/_C.cpython-39-x86_64-linux-gnu.so\n",
            "  running install_lib\n",
            "  creating /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiOps.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/sparse_matrix_functions.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiKernelGenerator.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/__init__.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  creating /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/modules\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/modules/__init__.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/modules\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/modules/senet_block.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/modules\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/modules/resnet_block.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/modules\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiNetwork.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/diagnostics.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiNormalization.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiFunctional.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiTensorField.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiCoordinateManager.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  creating /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/utils/__init__.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/utils/init.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/utils/coords.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/utils/quantization.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/utils/summary.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/utils/gradcheck.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/utils/collation.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiBroadcast.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiPooling.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiUnion.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiInterpolation.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiConvolution.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiSparseTensor.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiCommon.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiNonlinearity.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiChannelwiseConvolution.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiPruning.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngine/MinkowskiTensor.py -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngine\n",
            "  creating /usr/local/lib/python3.9/dist-packages/MinkowskiEngineBackend\n",
            "  copying build/lib.linux-x86_64-3.9/MinkowskiEngineBackend/_C.cpython-39-x86_64-linux-gnu.so -> /usr/local/lib/python3.9/dist-packages/MinkowskiEngineBackend\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiOps.py to MinkowskiOps.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/sparse_matrix_functions.py to sparse_matrix_functions.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiKernelGenerator.py to MinkowskiKernelGenerator.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/modules/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/modules/senet_block.py to senet_block.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/modules/resnet_block.py to resnet_block.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiNetwork.py to MinkowskiNetwork.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/diagnostics.py to diagnostics.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiNormalization.py to MinkowskiNormalization.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiFunctional.py to MinkowskiFunctional.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiTensorField.py to MinkowskiTensorField.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiCoordinateManager.py to MinkowskiCoordinateManager.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils/__init__.py to __init__.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils/init.py to init.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils/coords.py to coords.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils/quantization.py to quantization.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils/summary.py to summary.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils/gradcheck.py to gradcheck.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/utils/collation.py to collation.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiBroadcast.py to MinkowskiBroadcast.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiPooling.py to MinkowskiPooling.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiUnion.py to MinkowskiUnion.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiInterpolation.py to MinkowskiInterpolation.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiConvolution.py to MinkowskiConvolution.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiSparseTensor.py to MinkowskiSparseTensor.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiCommon.py to MinkowskiCommon.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiNonlinearity.py to MinkowskiNonlinearity.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiChannelwiseConvolution.py to MinkowskiChannelwiseConvolution.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiPruning.py to MinkowskiPruning.cpython-39.pyc\n",
            "  byte-compiling /usr/local/lib/python3.9/dist-packages/MinkowskiEngine/MinkowskiTensor.py to MinkowskiTensor.cpython-39.pyc\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating MinkowskiEngine.egg-info\n",
            "  writing MinkowskiEngine.egg-info/PKG-INFO\n",
            "  writing dependency_links to MinkowskiEngine.egg-info/dependency_links.txt\n",
            "  writing requirements to MinkowskiEngine.egg-info/requires.txt\n",
            "  writing top-level names to MinkowskiEngine.egg-info/top_level.txt\n",
            "  writing manifest file 'MinkowskiEngine.egg-info/SOURCES.txt'\n",
            "  reading manifest file 'MinkowskiEngine.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'MinkowskiEngine.egg-info/SOURCES.txt'\n",
            "  Copying MinkowskiEngine.egg-info to /usr/local/lib/python3.9/dist-packages/MinkowskiEngine-0.5.4-py3.9.egg-info\n",
            "  running install_scripts\n",
            "  writing list of installed files to '/tmp/pip-record-uuxytqwp/install-record.txt'\n",
            "  Running setup.py install for MinkowskiEngine ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed MinkowskiEngine-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U git+https://github.com/NVIDIA/MinkowskiEngine -v --no-deps \\\n",
        "                          --install-option=\"--force_cuda\" \\\n",
        "                          --install-option=\"--blas=openblas\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4875tA9ewsz8"
      },
      "source": [
        "5. Проверка, что все работает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aRF9-L9-wsz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c63196-dca6-4007-c104-a1d8b61ec57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is CUDA available in torch?: True\n",
            "Is CUDA available in MinkowskiEngine?: True\n",
            "==========System==========\n",
            "Linux-5.10.147+-x86_64-with-glibc2.31\n",
            "3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n",
            "==========Pytorch==========\n",
            "1.13.1+cu117\n",
            "torch.cuda.is_available(): True\n",
            "==========NVIDIA-SMI==========\n",
            "Driver Version 525.85.12\n",
            "CUDA Version 12.0\n",
            "VBIOS Version 90.04.A7.00.01\n",
            "Image Version G183.0200.00.02\n",
            "GSP Firmware Version N/A\n",
            "==========NVCC==========\n",
            "==========CC==========\n",
            "==========MinkowskiEngine==========\n",
            "0.5.4\n",
            "MinkowskiEngine compiled with CUDA Support: True\n",
            "NVCC version MinkowskiEngine is compiled: 11080\n",
            "CUDART version MinkowskiEngine is compiled: 11080\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"Is CUDA available in torch?: {torch.cuda.is_available()}\")\n",
        "import MinkowskiEngine as ME\n",
        "print(f\"Is CUDA available in MinkowskiEngine?: {ME.is_cuda_available()}\")\n",
        "ME.print_diagnostics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKVW9KZzwsz8"
      },
      "source": [
        "6. Финальный шаг - установка библиотеки [opr](https://github.com/alexmelekhin/open_place_recognition), код из которой будет использоваться в бейзлайне"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-wSNoVLQwsz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c95f96f7-cae1-4c09-c047-1a82e59c3891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'open_place_recognition'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 143 (delta 22), reused 16 (delta 16), pack-reused 105\u001b[K\n",
            "Receiving objects: 100% (143/143), 51.06 KiB | 231.00 KiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "/content/open_place_recognition\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/open_place_recognition\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-metric-learning\n",
            "  Downloading pytorch_metric_learning-2.1.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from opr==0.1.1) (1.10.1)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.9/dist-packages (from opr==0.1.1) (1.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from opr==0.1.1) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from opr==0.1.1) (4.7.0.72)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from opr==0.1.1) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from opr==0.1.1) (4.65.0)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations->opr==0.1.1) (0.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations->opr==0.1.1) (6.0)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations->opr==0.1.1) (0.19.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations->opr==0.1.1) (4.7.0.72)\n",
            "Collecting omegaconf<2.4,>=2.2\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from hydra-core->opr==0.1.1) (23.1)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->opr==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->opr==0.1.1) (2022.7.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-metric-learning->opr==0.1.1) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from pytorch-metric-learning->opr==0.1.1) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->opr==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations->opr==0.1.1) (4.5.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations->opr==0.1.1) (2023.4.12)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations->opr==0.1.1) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations->opr==0.1.1) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations->opr==0.1.1) (8.4.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations->opr==0.1.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->pytorch-metric-learning->opr==0.1.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->pytorch-metric-learning->opr==0.1.1) (3.1.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning->opr==0.1.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning->opr==0.1.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning->opr==0.1.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->pytorch-metric-learning->opr==0.1.1) (8.5.0.96)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->pytorch-metric-learning->opr==0.1.1) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->pytorch-metric-learning->opr==0.1.1) (67.7.2)\n",
            "Building wheels for collected packages: opr, antlr4-python3-runtime\n",
            "  Building editable for opr (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opr: filename=opr-0.1.1-0.editable-py3-none-any.whl size=3262 sha256=dd64f51fda61beafc4aa71142808e7468e258e203b98d750dbaf3f8601c98a99\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p86hfryp/wheels/fc/6e/46/8d72749dfa7887bcdccbc4ebd87174be996e9b918989097cd3\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=4808554b2df34cff868a3bf5bd802200feba71476aefd58256778493fa52452e\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
            "Successfully built opr antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core, pytorch-metric-learning, opr\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0 opr-0.1.1 pytorch-metric-learning-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alexmelekhin/open_place_recognition\n",
        "%cd open_place_recognition\n",
        "!pip install -e .  # флаг -e необходим для возможности редактировать код уже установленной библиотеки\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhz8U3ikwsz9"
      },
      "source": [
        "## Загрузка датасета в Google Colab\n",
        "\n",
        "Пример кода для загрузки датасета."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4QxWqOAwsz9"
      },
      "source": [
        "Вы можете воспользоваться утилитой gdown, которая по умолчанию доступна в Colab. Допустим, https://drive.google.com/file/d/1EdOTVgBJxsNUMecne7Fs4obJdJnDuJ18/view?usp=share_link\n",
        "\n",
        "https://drive.google.com/file/d/1mNdoFi_cd7uruX6QoD2sG-9TxKyeWFgP/view?usp=sharing\n",
        "\n",
        " - ссылка на файл. Чтобы скачать его, нам нужно передать в gdown в качестве аргумента его id - для данного примера это `1EdOTVgBJxsNUMecne7Fs4obJdJnDuJ18`\n",
        " \n",
        " '1mNdoFi_cd7uruX6QoD2sG-9TxKyeWFgP'\n",
        " (часть ссылки между `file/d/` и `/view`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://github.com/nytimes/covid-19-data/archive/refs/heads/master.zip\n",
        "\n",
        "#!unzip /content/master.zip"
      ],
      "metadata": {
        "id": "GZdIS0JJT7wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#public\n",
        "#!gdown --fuzzy https://drive.google.com/file/d/1P_pHnamCzX3PDrjC1X3xWcs3WItMwdef/view?usp=sharing\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1ga1Ppx-juVb7Nfom5yVLLVIwCWtTUWo7/view?usp=sharing\n",
        "#private\n",
        "#!gdown --fuzzy https://drive.google.com/file/d/1iPeBywoKywebY_BtlCRjQJsjrmuNUqGM/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H2XaUBZUJBP",
        "outputId": "0bfebcef-1ff6-4aa1-e473-b7b1dfc03db0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ga1Ppx-juVb7Nfom5yVLLVIwCWtTUWo7\n",
            "To: /content/public.zip\n",
            "100% 4.85G/4.85G [01:42<00:00, 47.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEsOL8j4wsz-"
      },
      "outputs": [],
      "source": [
        "#!gdown 1EdOTVgBJxsNUMecne7Fs4obJdJnDuJ18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaS2q5fIwsz-"
      },
      "source": [
        "Вы можете сверить хэш-сумму файла:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z5sIdZAwsz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774994d4-1b8a-4e7f-8e01-f95f36902452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f59cf87bb0ea380431c9dc889cc49d32dd1e985b8c4700b7155629cca34d5da6  public.zip\n"
          ]
        }
      ],
      "source": [
        "!sha256sum public.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct0YvYSnwsz-"
      },
      "source": [
        "И распаковать архив:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "D0R0Gu6rwsz-"
      },
      "outputs": [],
      "source": [
        "!unzip -q public.zip\n",
        "#!unzip -q obfuscated_private.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOR0HAofwsz_"
      },
      "source": [
        "## Базовое решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwIQ8ohLwsz_"
      },
      "source": [
        "Загрузите веса MinkLoc++, предобученного на датасете Oxford RobotCar по ссылке: https://drive.google.com/file/d/1zlfdX217Nh3_QL5r0XAHUjDFjIPxUmMg/view?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p9wfDN8zwsz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fb5a66-9cd0-4e87-a789-7ee88d3ff933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gLZtrKvZzLwRVY89hu4PWjJGfGQz32dt\n",
            "To: /content/baseline_minkloc_multimodal.pth\n",
            "100% 41.7M/41.7M [00:00<00:00, 196MB/s]\n"
          ]
        }
      ],
      "source": [
        "# если вы в colab'е:\n",
        "#!gdown 1zlfdX217Nh3_QL5r0XAHUjDFjIPxUmMg\n",
        "\n",
        "#baseline_minkloc_multimodal.pth\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1gLZtrKvZzLwRVY89hu4PWjJGfGQz32dt/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9YjC6cs_wsz_"
      },
      "outputs": [],
      "source": [
        "from opr.models import minkloc_multimodal\n",
        "\n",
        "model = minkloc_multimodal(weights=\"baseline_minkloc_multimodal.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-zfKSGxgsQF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ihy6B-vWws0A"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "IMAGE_LR = 0.0001\n",
        "CLOUD_LR = 0.001\n",
        "FUSION_LR = 0.001\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "SCHEDULER_GAMMA = 0.1\n",
        "SCHEDULER_STEPS = [5]\n",
        "\n",
        "DEVICE = \"cuda\"\n",
        "BATCH_EXPANSION_TH = None\n",
        "CHECKPOINTS_DIR = Path(\"checkpoints\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbqBeiYwws0A"
      },
      "source": [
        "Для инициализации функции лосса предлагается воспользоваться средствами библиотеки [Hydra](https://hydra.cc/docs/intro/).\n",
        "\n",
        "Примеры готовых конфиг-файлов есть в директории \"configs\" [репозитория opr](https://github.com/alexmelekhin/open_place_recognition). Обратите внимание, что в конфигурации датасета необходимо указать путь к его директории."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "akESHfcaws0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7c024a-1fa6-40be-98d0-38788174316a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "from opr.datasets.dataloader_factory import make_dataloaders\n",
        "\n",
        "LOSS_CFG_PATH = \"/content/open_place_recognition/configs/losses/triplet_margin.yaml\"\n",
        "DATASET_CFG_PATH = \"/content/open_place_recognition/configs/datasets/phystech_campus.yaml\"\n",
        "\n",
        "loss_cfg = OmegaConf.load(LOSS_CFG_PATH)\n",
        "loss_fn = instantiate(loss_cfg)\n",
        "\n",
        "dataset_cfg = OmegaConf.load(DATASET_CFG_PATH)\n",
        "#dataset_cfg.dataset.dataset_root = \"/content/public\"\n",
        "dataset_cfg.dataset.dataset_root = \"/content/obfuscated_private\"  # change path скачанный ячейкой выше\n",
        "\n",
        "dataloaders = make_dataloaders(\n",
        "    dataset_cfg=dataset_cfg.dataset,\n",
        "    batch_sampler_cfg=dataset_cfg.sampler,\n",
        "    num_workers=dataset_cfg.num_workers,\n",
        ")\n",
        "\n",
        "params_list = []\n",
        "if model.image_module is not None and IMAGE_LR is not None:\n",
        "    params_list.append({\"params\": model.image_module.parameters(), \"lr\": IMAGE_LR})\n",
        "if model.cloud_module is not None and CLOUD_LR is not None:\n",
        "    params_list.append({\"params\": model.cloud_module.parameters(), \"lr\": CLOUD_LR})\n",
        "if model.fusion_module is not None and FUSION_LR is not None:\n",
        "    params_list.append({\"params\": model.fusion_module.parameters(), \"lr\": FUSION_LR})\n",
        "optimizer = Adam(params_list, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = MultiStepLR(optimizer, milestones=SCHEDULER_STEPS, gamma=SCHEDULER_GAMMA)\n",
        "\n",
        "if not CHECKPOINTS_DIR.exists():\n",
        "    CHECKPOINTS_DIR.mkdir(parents=True)\n",
        "\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONINUE TRAINING\n",
        "model = minkloc_multimodal(weights=\"/content/checkpoints/epoch_19.pth\")\n",
        "\n",
        "#model = torch.load(\"best20.pth\")\n",
        "#model.eval()\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "EPOCHS = 21\n",
        "\n",
        "IMAGE_LR = 0.0001 * 0.01\n",
        "CLOUD_LR = 0.001 * 0.01\n",
        "FUSION_LR = 0.001 * 0.01\n",
        "WEIGHT_DECAY = 0.0001 * 0.01\n",
        "\n",
        "SCHEDULER_GAMMA = 0.6\n",
        "SCHEDULER_STEPS = [12]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "LOSS_CFG_PATH = \"/content/open_place_recognition/configs/losses/triplet_margin.yaml\"\n",
        "DATASET_CFG_PATH = \"/content/open_place_recognition/configs/datasets/phystech_campus.yaml\"\n",
        "\n",
        "loss_cfg = OmegaConf.load(LOSS_CFG_PATH)\n",
        "loss_fn = instantiate(loss_cfg)\n",
        "\n",
        "dataset_cfg = OmegaConf.load(DATASET_CFG_PATH)\n",
        "#dataset_cfg.dataset.dataset_root = \"/content/public\"\n",
        "dataset_cfg.dataset.dataset_root = \"/content/obfuscated_private\"  # change path скачанный ячейкой выше\n",
        "\n",
        "dataloaders = make_dataloaders(\n",
        "    dataset_cfg=dataset_cfg.dataset,\n",
        "    batch_sampler_cfg=dataset_cfg.sampler,\n",
        "    num_workers=dataset_cfg.num_workers,\n",
        ")\n",
        "\n",
        "params_list = []\n",
        "if model.image_module is not None and IMAGE_LR is not None:\n",
        "    params_list.append({\"params\": model.image_module.parameters(), \"lr\": IMAGE_LR})\n",
        "if model.cloud_module is not None and CLOUD_LR is not None:\n",
        "    params_list.append({\"params\": model.cloud_module.parameters(), \"lr\": CLOUD_LR})\n",
        "if model.fusion_module is not None and FUSION_LR is not None:\n",
        "    params_list.append({\"params\": model.fusion_module.parameters(), \"lr\": FUSION_LR})\n",
        "optimizer = Adam(params_list, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = MultiStepLR(optimizer, milestones=SCHEDULER_STEPS, gamma=SCHEDULER_GAMMA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KDa9SG27hYR",
        "outputId": "7c0df981-c79a-47e5-8c04-679f66e2fb61"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FFK5AaKTws0A"
      },
      "outputs": [],
      "source": [
        "from opr.testing import test\n",
        "\n",
        "\n",
        "# recall_at_n, recall_at_one_percent, mean_top1_distance = test(\n",
        "#     model=model,\n",
        "#     descriptor_key=\"fusion\",\n",
        "#     dataloader=dataloaders[\"test\"],\n",
        "#     dist_thresh=5.0,\n",
        "#     device=DEVICE,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Lqnn82DZws0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ca6ff7-4b5f-47f0-d410-950808c78f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1.]\n"
          ]
        }
      ],
      "source": [
        "print(recall_at_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVTlB2pyws0B"
      },
      "source": [
        "### Цикл обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "15F7hRXCws0B"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from opr.training import epoch_loop\n",
        "\n",
        "\n",
        "# best_recall_at_1 = 0.0\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     print(f\"\\n\\n=====> Epoch {epoch+1}:\")\n",
        "#     train_batch_size = dataloaders[\"train\"].batch_sampler.batch_size\n",
        "\n",
        "#     print(\"\\n=> Training:\\n\")\n",
        "\n",
        "#     train_stats, train_rate_non_zero = epoch_loop(\n",
        "#         dataloader=dataloaders[\"train\"],\n",
        "#         model=model,\n",
        "#         loss_fn=loss_fn,\n",
        "#         optimizer=optimizer,\n",
        "#         scheduler=scheduler,\n",
        "#         phase=\"train\",\n",
        "#         device=DEVICE,\n",
        "#     )\n",
        "\n",
        "#     print(f\"\\ntrain_rate_non_zero = {train_rate_non_zero}\")\n",
        "\n",
        "#     if BATCH_EXPANSION_TH is not None:\n",
        "#         if BATCH_EXPANSION_TH == 1.0:\n",
        "#             print(\"Batch expansion rate is set to every epoch. Increasing batch size.\")\n",
        "#             dataloaders[\"train\"].batch_sampler.expand_batch()\n",
        "#         elif train_rate_non_zero is None:\n",
        "#             print(\n",
        "#                 \"\\nWARNING: 'BATCH_EXPANSION_TH' was set, but 'train_rate_non_zero' is None. \",\n",
        "#                 \"The batch size was not expanded.\",\n",
        "#             )\n",
        "#         elif train_rate_non_zero < BATCH_EXPANSION_TH:\n",
        "#             print(\n",
        "#                 \"Average non-zero triplet ratio is less than threshold: \",\n",
        "#                 f\"{train_rate_non_zero} < {BATCH_EXPANSION_TH}\",\n",
        "#             )\n",
        "#             dataloaders[\"train\"].batch_sampler.expand_batch()\n",
        "\n",
        "#     print(\"\\n=> Validating:\\n\")\n",
        "\n",
        "#     val_stats, val_rate_non_zero = epoch_loop(\n",
        "#         dataloader=dataloaders[\"val\"],\n",
        "#         model=model,\n",
        "#         loss_fn=loss_fn,\n",
        "#         optimizer=optimizer,\n",
        "#         phase=\"val\",\n",
        "#         device=DEVICE,\n",
        "#     )\n",
        "\n",
        "#     print(f\"\\nval_rate_non_zero = {val_rate_non_zero}\")\n",
        "\n",
        "#     print(\"\\n=> Testing:\\n\")\n",
        "\n",
        "#     recall_at_n, recall_at_one_percent, mean_top1_distance = test(\n",
        "#         model=model,\n",
        "#         descriptor_key=\"fusion\",\n",
        "#         dataloader=dataloaders[\"test\"],\n",
        "#         dist_thresh=5.0,\n",
        "#         device=DEVICE,\n",
        "#     )\n",
        "\n",
        "#     stats_dict = {}\n",
        "#     stats_dict[\"test\"] = {\n",
        "#         \"mean_top1_distance\": mean_top1_distance,\n",
        "#         \"recall_at_1%\": recall_at_one_percent,\n",
        "#         \"recall_at_1\": recall_at_n[0],\n",
        "#         \"recall_at_3\": recall_at_n[2],\n",
        "#         \"recall_at_5\": recall_at_n[4],\n",
        "#         \"recall_at_10\": recall_at_n[9],\n",
        "#     }\n",
        "#     stats_dict[\"train\"] = train_stats\n",
        "#     stats_dict[\"train\"][\"batch_size\"] = train_batch_size\n",
        "\n",
        "#     # saving checkpoints\n",
        "#     checkpoint_dict = {\n",
        "#         \"epoch\": epoch + 1,\n",
        "#         \"stats_dict\": stats_dict,\n",
        "#         \"model_state_dict\": model.state_dict(),\n",
        "#         \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "#     }\n",
        "#     torch.save(checkpoint_dict, CHECKPOINTS_DIR / f\"epoch_{epoch+1}.pth\")\n",
        "#     if recall_at_n[0] > best_recall_at_1:\n",
        "#         print(\"Recall@1 improved!\")\n",
        "#         torch.save(checkpoint_dict, CHECKPOINTS_DIR / \"best.pth\")\n",
        "#         best_recall_at_1 = recall_at_n[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(checkpoint_dict, CHECKPOINTS_DIR / \"best20.pth\")"
      ],
      "metadata": {
        "id": "pRsyBb79k5sc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from opr.training import epoch_loop\n",
        "\n",
        "\n",
        "best_recall_at_1 = 0.0\n",
        "\n",
        "# ADDED evaluation skip\n",
        "EVAL_EVERY = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n\\n=====> Epoch {epoch+1}:\")\n",
        "    train_batch_size = dataloaders[\"train\"].batch_sampler.batch_size\n",
        "\n",
        "    print(\"\\n=> Training:\\n\")\n",
        "\n",
        "    train_stats, train_rate_non_zero = epoch_loop(\n",
        "        dataloader=dataloaders[\"train\"],\n",
        "        model=model,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        phase=\"train\",\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    print(f\"\\ntrain_rate_non_zero = {train_rate_non_zero}\")\n",
        "\n",
        "    if BATCH_EXPANSION_TH is not None:\n",
        "        if BATCH_EXPANSION_TH == 1.0:\n",
        "            print(\"Batch expansion rate is set to every epoch. Increasing batch size.\")\n",
        "            dataloaders[\"train\"].batch_sampler.expand_batch()\n",
        "        elif train_rate_non_zero is None:\n",
        "            print(\n",
        "                \"\\nWARNING: 'BATCH_EXPANSION_TH' was set, but 'train_rate_non_zero' is None. \",\n",
        "                \"The batch size was not expanded.\",\n",
        "            )\n",
        "        elif train_rate_non_zero < BATCH_EXPANSION_TH:\n",
        "            print(\n",
        "                \"Average non-zero triplet ratio is less than threshold: \",\n",
        "                f\"{train_rate_non_zero} < {BATCH_EXPANSION_TH}\",\n",
        "            )\n",
        "            dataloaders[\"train\"].batch_sampler.expand_batch()\n",
        "\n",
        "    # ADDED evaluation skip\n",
        "    if epoch % EVAL_EVERY == 0:\n",
        "        print(\"\\n=> Validating:\\n\")\n",
        "\n",
        "        val_stats, val_rate_non_zero = epoch_loop(\n",
        "            dataloader=dataloaders[\"val\"],\n",
        "            model=model,\n",
        "            loss_fn=loss_fn,\n",
        "            optimizer=optimizer,\n",
        "            phase=\"val\",\n",
        "            device=DEVICE,\n",
        "        )\n",
        "\n",
        "        print(f\"\\nval_rate_non_zero = {val_rate_non_zero}\")\n",
        "\n",
        "        print(\"\\n=> Testing:\\n\")\n",
        "\n",
        "        recall_at_n, recall_at_one_percent, mean_top1_distance = test(\n",
        "            model=model,\n",
        "            descriptor_key=\"fusion\",\n",
        "            dataloader=dataloaders[\"test\"],\n",
        "            dist_thresh=5.0,\n",
        "            device=DEVICE,\n",
        "        )\n",
        "\n",
        "        stats_dict = {}\n",
        "        stats_dict[\"test\"] = {\n",
        "            \"mean_top1_distance\": mean_top1_distance,\n",
        "            \"recall_at_1%\": recall_at_one_percent,\n",
        "            \"recall_at_1\": recall_at_n[0],\n",
        "            \"recall_at_3\": recall_at_n[2],\n",
        "            \"recall_at_5\": recall_at_n[4],\n",
        "            \"recall_at_10\": recall_at_n[9],\n",
        "        }\n",
        "        stats_dict[\"train\"] = train_stats\n",
        "        stats_dict[\"train\"][\"batch_size\"] = train_batch_size\n",
        "\n",
        "        # saving checkpoints\n",
        "        checkpoint_dict = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"stats_dict\": stats_dict,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        }\n",
        "        torch.save(checkpoint_dict, CHECKPOINTS_DIR / f\"epoch_{epoch+1}.pth\")\n",
        "        if recall_at_n[0] > best_recall_at_1:\n",
        "            print(\"Recall@1 improved!\")\n",
        "            torch.save(checkpoint_dict, CHECKPOINTS_DIR / \"best.pth\")\n",
        "            best_recall_at_1 = recall_at_n[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgn_KEK5xBm6",
        "outputId": "6c7e745f-423c-4a05-80c0-e4a9d0214f86"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "=====> Epoch 1:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train: 100%|██████████| 123/123 [01:32<00:00,  1.32it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "train_rate_non_zero = 0.6456905109344133\n",
            "\n",
            "=> Validating:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 100%|██████████| 123/123 [00:52<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val_rate_non_zero = 0.3306754221388368\n",
            "\n",
            "=> Testing:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 116/116 [00:49<00:00,  2.35it/s]\n",
            "Calculating metrics: 100%|██████████| 6/6 [00:01<00:00,  5.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Recall@N:\n",
            "[0.8452037  0.93009221 0.95474751 0.96334693 0.9680724  0.97197141\n",
            " 0.97583497 0.97721807 0.97914196 0.98134654 0.98299406 0.98523662\n",
            " 0.98663044 0.9871751  0.98801681 0.98856641 0.98967994 0.99023841\n",
            " 0.99108332 0.99108332 0.99135565 0.99163068 0.99217983 0.99217983\n",
            " 0.99217983]\n",
            "Mean Recall@1% = 0.9719714143838131\n",
            "Mean top-1 distance = 1.340318461293676\n",
            "Recall@1 improved!\n",
            "\n",
            "\n",
            "=====> Epoch 2:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "train: 124it [01:32,  1.34it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "train_rate_non_zero = 0.3815070010634527\n",
            "\n",
            "\n",
            "=====> Epoch 3:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train:  99%|█████████▉| 123/124 [01:30<00:00,  1.36it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "train_rate_non_zero = 0.3093938920158432\n",
            "\n",
            "\n",
            "=====> Epoch 4:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 123/123 [01:29<00:00,  1.38it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "train_rate_non_zero = 0.24739269312440046\n",
            "\n",
            "=> Validating:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 124it [00:51,  2.40it/s]                         \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val_rate_non_zero = 0.16740776025050216\n",
            "\n",
            "=> Testing:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 116/116 [00:47<00:00,  2.43it/s]\n",
            "Calculating metrics: 100%|██████████| 6/6 [00:01<00:00,  5.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Recall@N:\n",
            "[0.88438922 0.95991768 0.97799637 0.98413451 0.98689021 0.98857384\n",
            " 0.99051026 0.99160452 0.99242691 0.99326046 0.99409626 0.99437971\n",
            " 0.99522117 0.99551053 0.99551053 0.99551053 0.9957883  0.99634408\n",
            " 0.99692279 0.99719736 0.99719736 0.99748081 0.99748081 0.99748081\n",
            " 0.99748081]\n",
            "Mean Recall@1% = 0.9885738391925406\n",
            "Mean top-1 distance = 1.7029118164075066\n",
            "Recall@1 improved!\n",
            "\n",
            "\n",
            "=====> Epoch 5:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "train: 124it [01:30,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.21529710209145692\n",
            "\n",
            "\n",
            "=====> Epoch 6:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 100%|██████████| 124/124 [01:28<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.1947178381654188\n",
            "\n",
            "\n",
            "=====> Epoch 7:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 100%|██████████| 124/124 [01:28<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.16515760225437645\n",
            "\n",
            "=> Validating:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "val:  99%|█████████▉| 123/124 [00:51<00:00,  2.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "val_rate_non_zero = 0.10883513505464726\n",
            "\n",
            "=> Testing:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 116/116 [00:48<00:00,  2.42it/s]\n",
            "Calculating metrics: 100%|██████████| 6/6 [00:01<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Recall@N:\n",
            "[0.89833728 0.97384052 0.98661618 0.99105573 0.993029   0.99387682\n",
            " 0.99581621 0.99692159 0.99748872 0.99748872 0.99777217 0.99777217\n",
            " 0.99777217 0.99777217 0.99777217 0.99777217 0.99777217 0.99777217\n",
            " 0.99777217 0.99805561 0.99833339 0.99860796 0.99860796 0.99860796\n",
            " 0.99889141]\n",
            "Mean Recall@1% = 0.9938768211801877\n",
            "Mean top-1 distance = 1.783278724300575\n",
            "Recall@1 improved!\n",
            "\n",
            "\n",
            "=====> Epoch 8:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "train:  99%|█████████▉| 123/124 [01:29<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.15755407645651548\n",
            "\n",
            "\n",
            "=====> Epoch 9:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 124it [01:29,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.13928188746737136\n",
            "\n",
            "\n",
            "=====> Epoch 10:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 100%|██████████| 124/124 [01:29<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.14659375123084803\n",
            "\n",
            "=> Validating:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "val: 100%|██████████| 123/123 [00:50<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "val_rate_non_zero = 0.08337762057274252\n",
            "\n",
            "=> Testing:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 116/116 [00:49<00:00,  2.36it/s]\n",
            "Calculating metrics: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Recall@N:\n",
            "[0.90693927 0.97498114 0.987442   0.99078436 0.99302876 0.99498517\n",
            " 0.99611032 0.99638265 0.99748281 0.99777217 0.99806152 0.99806152\n",
            " 0.99861163 0.99861163 0.99888396 0.99888396 0.99945085 0.99945085\n",
            " 0.99945085 0.99945085 0.99945085 0.99945085 0.99945085 0.99945085\n",
            " 0.99972543]\n",
            "Mean Recall@1% = 0.9949851681218247\n",
            "Mean top-1 distance = 1.789142531993006\n",
            "Recall@1 improved!\n",
            "\n",
            "\n",
            "=====> Epoch 11:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "train:  99%|█████████▉| 123/124 [01:27<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.14589463156536328\n",
            "\n",
            "\n",
            "=====> Epoch 12:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 124it [01:28,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.13671307411226766\n",
            "\n",
            "\n",
            "=====> Epoch 13:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 100%|██████████| 124/124 [01:27<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.14842463763834732\n",
            "\n",
            "=> Validating:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "val: 124it [00:51,  2.41it/s]                         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "val_rate_non_zero = 0.07085536551262357\n",
            "\n",
            "=> Testing:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 116/116 [00:47<00:00,  2.45it/s]\n",
            "Calculating metrics: 100%|██████████| 6/6 [00:01<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Recall@N:\n",
            "[0.90894475 0.97665846 0.98883902 0.99221268 0.99444646 0.99610808\n",
            " 0.99667245 0.99778919 0.99806152 0.99806152 0.99806152 0.99806152\n",
            " 0.99834496 0.99889507 0.99889507 0.99916965 0.99916965 0.99916965\n",
            " 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543\n",
            " 0.99972543]\n",
            "Mean Recall@1% = 0.9961080756181566\n",
            "Mean top-1 distance = 1.7715692231523341\n",
            "Recall@1 improved!\n",
            "\n",
            "\n",
            "=====> Epoch 14:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "train:  99%|█████████▉| 123/124 [01:26<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.13746091307066916\n",
            "\n",
            "\n",
            "=====> Epoch 15:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 100%|██████████| 123/123 [01:28<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.1367683017073261\n",
            "\n",
            "\n",
            "=====> Epoch 16:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  99%|█████████▉| 122/123 [01:27<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.14102076202486039\n",
            "\n",
            "=> Validating:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "val: 100%|██████████| 124/124 [00:51<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "val_rate_non_zero = 0.08672591968962935\n",
            "\n",
            "=> Testing:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 116/116 [00:47<00:00,  2.43it/s]\n",
            "Calculating metrics: 100%|██████████| 6/6 [00:01<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Recall@N:\n",
            "[0.91818648 0.97724494 0.98886716 0.99275935 0.99557499 0.9966747\n",
            " 0.99779486 0.99834496 0.99834496 0.99861954 0.99861954 0.99890299\n",
            " 0.99945309 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543\n",
            " 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543\n",
            " 0.99972543]\n",
            "Mean Recall@1% = 0.9966746982277396\n",
            "Mean top-1 distance = 1.7649931221490178\n",
            "Recall@1 improved!\n",
            "\n",
            "\n",
            "=====> Epoch 17:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "train: 123it [01:28,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.11851802217655878\n",
            "\n",
            "\n",
            "=====> Epoch 18:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 100%|██████████| 123/123 [01:27<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.1148442230759304\n",
            "\n",
            "\n",
            "=====> Epoch 19:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train: 124it [01:28,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.11502680786954982\n",
            "\n",
            "=> Validating:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "val: 100%|██████████| 124/124 [00:52<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "val_rate_non_zero = 0.07501303579932611\n",
            "\n",
            "=> Testing:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 116/116 [00:47<00:00,  2.42it/s]\n",
            "Calculating metrics: 100%|██████████| 6/6 [00:01<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Recall@N:\n",
            "[0.92371091 0.97888337 0.99053971 0.99332081 0.99472716 0.99694703\n",
            " 0.99807218 0.99835563 0.99863065 0.99890299 0.99917532 0.99917532\n",
            " 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543\n",
            " 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543 0.99972543\n",
            " 0.99972543]\n",
            "Mean Recall@1% = 0.9969470293824237\n",
            "Mean top-1 distance = 1.7796924923252206\n",
            "Recall@1 improved!\n",
            "\n",
            "\n",
            "=====> Epoch 20:\n",
            "\n",
            "=> Training:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "train:  98%|█████████▊| 122/124 [01:27<00:01,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_rate_non_zero = 0.12186693088332433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5TFZpy-Vws0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f80362-ab41-4c77-e962-d72525d02f12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComposedModel(\n",
              "  (image_module): ImageModule(\n",
              "    (backbone): ResNet18FPNExtractor(\n",
              "      (resnet_fe): ModuleList(\n",
              "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "        (4): Sequential(\n",
              "          (0): BasicBlock(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (1): BasicBlock(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (5): Sequential(\n",
              "          (0): BasicBlock(\n",
              "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): BasicBlock(\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (6): Sequential(\n",
              "          (0): BasicBlock(\n",
              "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): BasicBlock(\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (fh_tconvs): ModuleDict()\n",
              "      (fh_conv1x1): ModuleDict(\n",
              "        (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (head): GeM()\n",
              "  )\n",
              "  (cloud_module): CloudModule(\n",
              "    (backbone): MinkResNetFPNExtractor(\n",
              "      (convs): ModuleList(\n",
              "        (0): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])\n",
              "        (1): MinkowskiConvolution(in=32, out=32, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])\n",
              "        (2): MinkowskiConvolution(in=64, out=64, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])\n",
              "      )\n",
              "      (bn): ModuleList(\n",
              "        (0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (blocks): ModuleList(\n",
              "        (0): Sequential(\n",
              "          (0): MinkECABasicBlock(\n",
              "            (conv1): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "            (norm1): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): MinkowskiConvolution(in=32, out=32, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "            (norm2): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): MinkowskiReLU()\n",
              "            (eca): MinkECALayer(\n",
              "              (avg_pool): MinkowskiGlobalPooling(mode=PoolingMode.GLOBAL_AVG_POOLING_PYTORCH_INDEX)\n",
              "              (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "              (sigmoid): Sigmoid()\n",
              "              (broadcast_mul): MinkowskiBroadcastMultiplication\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): MinkECABasicBlock(\n",
              "            (conv1): MinkowskiConvolution(in=32, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): MinkowskiReLU()\n",
              "            (downsample): Sequential(\n",
              "              (0): MinkowskiConvolution(in=32, out=64, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "              (1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (eca): MinkECALayer(\n",
              "              (avg_pool): MinkowskiGlobalPooling(mode=PoolingMode.GLOBAL_AVG_POOLING_PYTORCH_INDEX)\n",
              "              (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "              (sigmoid): Sigmoid()\n",
              "              (broadcast_mul): MinkowskiBroadcastMultiplication\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): Sequential(\n",
              "          (0): MinkECABasicBlock(\n",
              "            (conv1): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "            (norm1): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): MinkowskiConvolution(in=64, out=64, kernel_size=[3, 3, 3], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "            (norm2): MinkowskiBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): MinkowskiReLU()\n",
              "            (eca): MinkECALayer(\n",
              "              (avg_pool): MinkowskiGlobalPooling(mode=PoolingMode.GLOBAL_AVG_POOLING_PYTORCH_INDEX)\n",
              "              (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "              (sigmoid): Sigmoid()\n",
              "              (broadcast_mul): MinkowskiBroadcastMultiplication\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (tconvs): ModuleList(\n",
              "        (0): MinkowskiConvolutionTranspose(in=128, out=128, kernel_size=[2, 2, 2], stride=[2, 2, 2], dilation=[1, 1, 1])\n",
              "      )\n",
              "      (conv1x1): ModuleList(\n",
              "        (0): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "        (1): MinkowskiConvolution(in=64, out=128, kernel_size=[1, 1, 1], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "      )\n",
              "      (conv0): MinkowskiConvolution(in=1, out=32, kernel_size=[5, 5, 5], stride=[1, 1, 1], dilation=[1, 1, 1])\n",
              "      (bn0): MinkowskiBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): MinkowskiReLU()\n",
              "    )\n",
              "    (head): MinkGeM(\n",
              "      (f): MinkowskiGlobalAvgPooling(mode=PoolingMode.GLOBAL_AVG_POOLING_PYTORCH_INDEX)\n",
              "    )\n",
              "  )\n",
              "  (fusion_module): Concat()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = minkloc_multimodal(weights=\"/content/checkpoints/epoch_16.pth\")\n",
        "\n",
        "#model = torch.load(\"best20.pth\")\n",
        "model.eval()\n",
        "\n",
        "# recall_at_n, recall_at_one_percent, mean_top1_distance = test(\n",
        "#     model=model,\n",
        "#     descriptor_key=\"fusion\",\n",
        "#     dataloader=dataloaders[\"test\"],\n",
        "#     dist_thresh=5.0,\n",
        "#     device=DEVICE,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62c62wEows0C"
      },
      "source": [
        "## Подготовка ответа для загрузки на сервер"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqsGbPOWws0C"
      },
      "source": [
        "Пример кода для создания файла сабмита. Вы можете модифицировать пайплайн, например добавить ре-ранжирование кандидатов на основе каких-либо характеристик (например, как в [Path-NetVLAD](https://arxiv.org/abs/2103.01486))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A9oeQwkQws0C"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KDTree\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def extract_embeddings(model, descriptor_key, dataloader, device):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_embeddings_list = []\n",
        "        for data in tqdm(dataloader, desc=\"Calculating test set descriptors\"):\n",
        "            batch, _, _ = data\n",
        "            batch = {e: batch[e].to(device) for e in batch}\n",
        "            batch_embeddings = model(batch)\n",
        "            test_embeddings_list.append(batch_embeddings[descriptor_key].cpu().numpy())\n",
        "        test_embeddings = np.vstack(test_embeddings_list)\n",
        "    return test_embeddings\n",
        "\n",
        "\n",
        "def test_submission(\n",
        "    test_embeddings: np.ndarray, dataset_df: pd.DataFrame, filename: str = \"submission.txt\"\n",
        ") -> None:\n",
        "    \"\"\"Function to create submission txt file.\n",
        "\n",
        "    Args:\n",
        "        test_embeddings (np.ndarray): Array of embeddings.\n",
        "        dataset_df (pd.Dataframe): Test dataset dataframe ('test.csv').\n",
        "        filename (str): Name of the output txt file. Defaults to \"submission.txt\".\n",
        "    \"\"\"\n",
        "    tracks = []\n",
        "\n",
        "    for _, group in dataset_df.groupby(\"track\"):\n",
        "        tracks.append(group.index.to_numpy())\n",
        "    n = 1\n",
        "    ij_permutations = sorted(list(itertools.permutations(range(len(tracks)), 2)))\n",
        "    # ij_permutations = [(0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1)]\n",
        "\n",
        "    submission_lines = []\n",
        "\n",
        "    for i, j in tqdm(ij_permutations, desc=\"Calculating metrics\"):\n",
        "        query_indices = tracks[i]\n",
        "        database_indices = tracks[j]\n",
        "        query_embs = test_embeddings[query_indices]\n",
        "        database_embs = test_embeddings[database_indices]\n",
        "\n",
        "        database_tree = KDTree(database_embs)\n",
        "        _, indices = database_tree.query(query_embs, k=n)\n",
        "\n",
        "        submission_lines.extend(list(database_indices[indices.squeeze()]))\n",
        "\n",
        "    with open(filename, \"w\") as f:\n",
        "        for l in submission_lines:\n",
        "            f.write(str(l)+\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "stFcnpGcws0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69b2f0f-e2a1-4781-b886-47122cc36c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating test set descriptors: 100%|██████████| 80/80 [00:33<00:00,  2.39it/s]\n",
            "Calculating metrics: 100%|██████████| 2/2 [00:00<00:00,  6.51it/s]\n"
          ]
        }
      ],
      "source": [
        "embeddings = extract_embeddings(model, descriptor_key=\"fusion\", dataloader=dataloaders[\"test\"], device=DEVICE)\n",
        "test_submission(embeddings, dataset_df=dataloaders[\"test\"].dataset.dataset_df, filename=\"private_submission_margin05_mink_quantization_size_0.06_epoch16full.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRVkwYquws0D"
      },
      "source": [
        "Файл с сабмитом необходимо загружать на яндекс контест: https://contest.yandex.ru/contest/49118/ \n",
        "\n",
        "Удачи!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sVizN2TKXMhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "test_df = pd.read_csv(\"/content/obfuscated_private/test.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def visualize(i: int, submission: List[int], df: pd.DataFrame):\n",
        "    # NOTE: это сработает на приватной части, а для публичной потребуются \n",
        "    # некоторые модификации (не только замена путей) :)\n",
        "    query_i = i\n",
        "    db_i = submission[query_i]\n",
        "\n",
        "    query_track = test_df.iloc[query_i][\"track\"]\n",
        "    query_front_cam_ts = test_df.iloc[query_i][\"front_cam_ts\"]\n",
        "    print(f\"query_track = {query_track}\")\n",
        "    db_track = test_df.iloc[db_i][\"track\"]\n",
        "    db_front_cam_ts = test_df.iloc[db_i][\"front_cam_ts\"]\n",
        "    print(f\"database_track = {db_track}\")\n",
        "\n",
        "    query_image = cv2.cvtColor(cv2.imread(\n",
        "        f\"/content/obfuscated_private/{query_track}/front_cam/{query_front_cam_ts}.png\"\n",
        "    ), cv2.COLOR_BGR2RGB)\n",
        "    db_image = cv2.cvtColor(cv2.imread(\n",
        "        f\"/content/obfuscated_private/{db_track}/front_cam/{db_front_cam_ts}.png\"\n",
        "    ), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(query_image)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(db_image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hphUhreXvSaL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eA66Yx8zXSVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}